<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Prashant Bhardwaj</title>
        <link>https://prashantbhardwaj.github.io/posts/</link>
        <description>Recent content in Posts on Prashant Bhardwaj</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>copyright@Prashant</copyright>
        <lastBuildDate>Sat, 14 Sep 2019 17:01:38 +0100</lastBuildDate>
        <atom:link href="https://prashantbhardwaj.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Cassandra : What is this?</title>
            <link>https://prashantbhardwaj.github.io/posts/2019/09/cassandra-what-is-this/</link>
            <pubDate>Sat, 14 Sep 2019 17:01:38 +0100</pubDate>
            
            <guid>https://prashantbhardwaj.github.io/posts/2019/09/cassandra-what-is-this/</guid>
            <description>Agenda  Characterstics How does it internally work References  The Apache Cassandra database is the right choice when you need scalability and high availability without compromising performance. Linear scalability and proven fault-tolerance on commodity hardware or cloud infrastructure make it the perfect platform for mission-critical data. Cassandra&amp;rsquo;s support for replicating across multiple datacenters is best-in-class, providing lower latency for your users and the peace of mind of knowing that you can survive regional outages.</description>
            <content type="html"><![CDATA[

<h2>Agenda</h2>

<ul>
<li><a href="#h2-characterstics-h2">Characterstics</a></li>
<li><a href="#h2-how-does-it-internally-work-h2">How does it internally work</a></li>
<li><a href="#h2-references-h2">References</a></li>
</ul>

<p>The Apache Cassandra database is the right choice when you need scalability and high availability without compromising performance. Linear scalability and proven fault-tolerance on commodity hardware or cloud infrastructure make it the perfect platform for mission-critical data. Cassandra&rsquo;s support for replicating across multiple datacenters is best-in-class, providing lower latency for your users and the peace of mind of knowing that you can survive regional outages.</p>

<h2 id="h2-characterstics-h2"><h2>Characterstics</h2></h2>

<p><strong>Fault tolerant</strong>
Data is automatically replicated to multiple nodes for fault-tolerance. Replication across multiple data centers is supported. Failed nodes can be replaced with no downtime.</p>

<p><strong>Performant</strong>
Cassandra consistently outperforms popular NoSQL alternatives in benchmarks and real applications, primarily because of fundamental architectural choices.</p>

<p><strong>Decentralized</strong>
There are no single points of failure. There are no network bottlenecks. Every node in the cluster is identical.</p>

<p><strong>Scalable</strong>
Some of the largest production deployments include Apple&rsquo;s, with over 75,000 nodes storing over 10 PB of data, Netflix (2,500 nodes, 420 TB, over 1 trillion requests per day), Chinese search engine Easou (270 nodes, 300 TB, over 800 million requests per day), and eBay (over 100 nodes, 250 TB).</p>

<p><strong>Durable</strong>
Cassandra is suitable for applications that can&rsquo;t afford to lose data, even when an entire data center goes down.</p>

<p><strong>You&rsquo;re in control</strong>
Choose between synchronous or asynchronous replication for each update. Highly available asynchronous operations are optimized with features like Hinted Handoff and Read Repair.</p>

<p><strong>Elastic</strong>
Read and write throughput both increase linearly as new machines are added, with no downtime or interruption to applications.</p>

<p><strong>Professionally Supported</strong>
Cassandra support contracts and services are available from third parties.</p>

<h2 id="h2-how-does-it-internally-work-h2"><h2>How does it internally work</h2></h2>

<h3>Fully replicated</h3>

<p><img src="/caas/caas-cluster.png" alt="alt text" /></p>

<ul>
<li>Client writes local</li>
<li>Data syncs across WAN</li>
<li>Replication factor per data center</li>
</ul>

<h3>Writes on a single node</h3>

<p><img src="/caas/cass-write.png" alt="alt text" /></p>

<p>Entire write happens in following steps</p>

<ul>
<li>Logging data in the commit log</li>
<li>Writing data to the memtable</li>
<li>Flushing data from the memtable</li>
<li>Storing data on disk in SSTables</li>
<li>Compaction</li>
</ul>

<p>First thing it does, is writing the data in commit log, which is on disc, because of that it is durable.
It is append only log which is sequencial write and that is the reason that write in Cassandra is super fast.</p>

<p>Then it writes data in memtable. The memtable is a write-back cache of data partitions that Cassandra looks up by key. The more a table is used, the larger its memtable needs to be. Cassandra can dynamically allocate the right amount of memory for the memtable or you can manage the amount of memory being utilized yourself.</p>

<p>Row in memtable can have 2 billion columns. After writing data in the column it sends acknowldgement back to client.</p>

<p>The memtable, unlike a write-through cache, stores writes until reaching a limit, and then is flushed. When memtable contents exceed a configurable threshold, the memtable data, which includes indexes, is put in a queue to be flushed to disk. To flush the data, Cassandra sorts memtables by partition key and then writes the data to disk sequentially. The process is extremely fast because it involves only a commitlog append and the sequential write.</p>

<p>SSTables are immutable, not written to again after the memtable is flushed. Consequently, a partition is typically stored across multiple SSTable files So, if a row is not in memtable, a read of the row needs look-up in all the SSTable files. This is why read in Cassandra is much slower than write.</p>

<p>Data in the commit log is purged after its corresponding data in the memtable is flushed to the SSTable. The commit log is for recovering the data in memtable in the event of a hardware failure.</p>

<p>as we know that data for a row in SSTable is not in just one SSTable. Whenever data in a row is updated Cassandra writes a new timestamped version of the inserted or updated data in another SSTable. Cassandra also does not delete in place because the SSTable is immutable. Instead, Cassandra marks data to be deleted using a tombstone. Tombstones exist for a configured time period defined by the gc_grace_seconds value set on the table. During compaction, there is a temporary spike in disk space usage and disk I/O because the old and new SSTables co-exist. This diagram depicts the compaction process:</p>

<p><img src="/caas/caas-compaction.png" alt="alt text" /></p>

<p>Compaction merges the data in each SSTable data by partition key, selecting the latest data for storage based on its timestamp. Cassandra can merge the data performantly, without random IO, because rows are sorted by partition key within each SSTable. After evicting tombstones and removing deleted data, columns, and rows, the compaction process consolidates SSTables into a single file. The old SSTable files are deleted as soon as any pending reads finish using the files. Disk space occupied by old SSTables becomes available for reuse.</p>

<p>Data input to SSTables is sorted to prevent random I/O during SSTable consolidation. After compaction, Cassandra uses the new consolidated SSTable instead of multiple old SSTables, fulfilling read requests more efficiently than before compaction. The old SSTable files are deleted as soon as any pending reads finish using the files. Disk space occupied by old SSTables becomes available for reuse.</p>

<p>Although no random I/O occurs, compaction can still be a fairly heavyweight operation. During compaction, there is a temporary spike in disk space usage and disk I/O because the old and new SSTables co-exist. To minimize deteriorating read speed, compaction runs in the background.</p>

<h3>Coordinated reads</h3>

<p><img src="/caas/caas-read.png" alt="alt text" /></p>

<p>When a read request starts its journey, the data’s partition key is used to find what nodes have the data. After that, the request is sent to a number of nodes set by the tunable consistency level for reads. Then, on each node, in a certain order, Cassandra checks different places that can have the data. The first one is the memtable. If the data is not there, it checks the row key cache (if enabled), then the bloom filter and then the partition key cache (also if enabled). If the partition key cache has the needed partition key, Cassandra goes straight to the compression offsets, and after that it finally fetches the needed data out of a certain SSTable. If the partition key wasn’t found in partition key cache, Cassandra checks the partition summary and then the primary index before going to the compression offsets and extracting the data from the SSTable.</p>

<p>After the data with the latest timestamp is located, it is fetched to the coordinator. Here, another stage of the read occurs. As we’ve stated here, Cassandra has issues with data consistency. The thing is that you write many data replicas and you may read their old versions instead of the newer ones. But Cassandra doesn’t ignore these consistency-related problems: it tries to solve them with a read repair process. The nodes that are involved in the read return results. Then, Cassandra compares these results based on the “last write wins” policy. Hence, the new data version is the main candidate to be returned to the user, while the older versions are rewritten to their nodes. But that’s not all. In the background, Cassandra checks the rest of the nodes that have the requested data (because the replication factor is often bigger than consistency level). When these nodes return results, the DB also compares them and the older ones get rewritten. Only after this, the user actually gets the result.</p>

<h2 id="h2-references-h2"><h2>References</h2></h2>

<ul>
<li><a href="https://docs.datastax.com/en/archived/cassandra/2.0/cassandra/dml/dml_write_path_c.html">https://docs.datastax.com/en/archived/cassandra/2.0/cassandra/dml/dml_write_path_c.html</a></li>
<li><a href="https://www.scnsoft.com/blog/cassandra-performance">https://www.scnsoft.com/blog/cassandra-performance</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Cassandra : When to use and how to use</title>
            <link>https://prashantbhardwaj.github.io/posts/2019/09/cassandra-when-to-use-and-how-to-use/</link>
            <pubDate>Mon, 09 Sep 2019 23:36:07 +0100</pubDate>
            
            <guid>https://prashantbhardwaj.github.io/posts/2019/09/cassandra-when-to-use-and-how-to-use/</guid>
            <description>I don&amp;rsquo;t think that I need to explain what Cassandra is. OK, one liner is enough ! It is NoSQL database, primarily used in big data projects.
Before we start discussing scenarios where Cassandra fits very well, let&amp;rsquo;s discuss where it doesn&amp;rsquo;t fit at all.
Common mistakes when using Cassandra We don&amp;rsquo;t have big data in the beginning however our data will grow and will become big one day Our organization has Cassandra running as a service so it is easy for us to atleast start with it Ohh !</description>
            <content type="html"><![CDATA[<p>I don&rsquo;t think that I need to explain what Cassandra is. OK, one liner is enough ! It is NoSQL database, primarily used in big data projects.</p>

<p>Before we start discussing scenarios where Cassandra fits very well, let&rsquo;s discuss where it doesn&rsquo;t fit at all.</p>

<p><strong>Common mistakes when using Cassandra</strong>
<strong>We don&rsquo;t have big data in the beginning however our data will grow and will become big one day</strong>
<strong>Our organization has Cassandra running as a service so it is easy for us to atleast start with it</strong>
<strong>Ohh ! CQL is just like SQL. Great !!, now we can query any data !</strong>
<strong>Ohh no, Cassandra doesn&rsquo;t allow manipulation of data during read or write</strong>
<strong>WoW, this User defined functions are great things, let&rsquo;s create many</strong></p>
]]></content>
        </item>
        
        <item>
            <title>Build your website using GoHugo and host it on GitHub Pages</title>
            <link>https://prashantbhardwaj.github.io/posts/2019/08/build-your-website-using-gohugo-and-host-it-on-github-pages/</link>
            <pubDate>Mon, 12 Aug 2019 23:22:50 +0100</pubDate>
            
            <guid>https://prashantbhardwaj.github.io/posts/2019/08/build-your-website-using-gohugo-and-host-it-on-github-pages/</guid>
            <description>Overview GitHub came up with GitHub pages service, which hosts static web content free of cost. For Tech bloggers and for those who are trying to make their hands dirty in static web content creation, this is the best service at this moment. Read tagline of GitHub Pages -
GoHugo is one of the most popular open-source static site generators. With its amazing speed and flexibility, GoHugo makes building websites fun again.</description>
            <content type="html"><![CDATA[

<h3 id="overview">Overview</h3>

<p><strong>GitHub</strong> came up with <a href="https://pages.github.com/">GitHub pages service</a>, which hosts static web content free of cost. For Tech bloggers and for those who are trying to make their hands dirty in static web content creation, this is the best service at this moment. Read tagline of GitHub Pages -</p>

<p><img src="/GitHub-pages-intro.PNG" alt="alt text" /></p>

<p><strong>GoHugo</strong> is one of the most popular open-source <a href="https://gohugo.io/">static site generators</a>. With its amazing speed and flexibility, GoHugo makes building websites fun again. It is <a href="https://themes.gohugo.io/">theme</a> based framework. You write markdown files and hugo creates static html by blending the content written in markdown files with the theme you selected. I am using <a href="https://themes.gohugo.io/hugo-theme-hello-friend-ng/">hello-friend-ng</a> theme for this website. And this entire post is written in single markdown file. Result is in-front of you. In future, I can choose any other theme and same content then will be presented differently on UI.</p>

<p><img src="/Hugo-intro.PNG" alt="alt text" /></p>

<p>Now, In this post I will explain the step by step procedure to create a personal blog site using Hugo and then hosting this on GitHubPages.</p>

<h3 id="step-1-repository-setup-in-github">Step 1 - Repository setup in GitHub</h3>

<h4 id="1-1-to-create-a-user-page-site-on-github-pages-create-a-repository-using-the-naming-scheme-lt-username-gt-github-io">1.1 - To create a User Page site on GitHub Pages, create a repository using the naming scheme  &lt;username&gt;.github.io.</h4>

<p>My GitHub username is prashantbhardwaj hence I created a repository with the name as <em>prashantbhardwaj.github.io</em>.
Now, when I will push any static web contents like HTML, CSS or JS files, those files will be hosted on GitHub Pages and can be accessed on this <a href="https://prashantbhardwaj.github.io">URL</a>. Please Note - Content from the master branch will be used to publish your GitHub Pages site.</p>

<h4 id="1-2-now-create-one-more-repository-to-keep-the-code-of-your-hugo-website-project">1.2 - Now create one more repository to keep the code of your Hugo Website project.</h4>

<p>GoHugo will be used to create static content of your website. To do so, you need a github repository to keep you Hugo project code. Finally that generated static content will be pushed into &lt;username&gt;.github.io repository. You can give any name for your GoHugo project repository. I chose <em>website</em>.</p>

<h4 id="please-note">Please note</h4>

<p>These two repository will remain blank until step 3. Later we will use these repositories to push static website content and the GoHugo code which will be used to generate these static web content.</p>

<h3 id="step-2-gohugo-installation">Step 2 - GoHugo installation</h3>

<p>To install GoHugo in your local machine, follow steps mentioned on this <a href="https://gohugo.io/getting-started/installing/">page</a>.</p>

<h3 id="step-3-learn-gohugo">Step 3 - Learn GoHugo</h3>

<p>Check this <a href="https://www.youtube.com/watch?v=qtIqKaDlqXo&amp;list=PLLAZ4kZ9dFpOnyRlyS-liKL5ReHDcj4G3">YouTube playlist</a>, to learn GoHugo, step by step. During this learning exercise you will also create your GoHugo website project.</p>

<h3 id="step-4-link-your-gohugo-project-to-your-github-repository">Step 4 - Link your GoHugo project to your github repository.</h3>

<p>I hope during learning GoHugo by watching the youtube clips mentioned in previous step, you created your project. Now, it is time to link your GoHugo project with your website project repository you created under step 1.2. Steps to link your project code with GitHub repository are mentioned on your GitHub repository home page. Open that home page on your GitHub repository website and follow them.</p>

<h3 id="step-5-link-your-theme-subproject-with-its-github-repository">Step 5 - Link your theme subproject with its github repository.</h3>

<p>I hope during learning GoHugo by watching the youtube clips mentioned in previous step, you created your project and if so then probably you downloaded your chosen theme from it&rsquo;s GitHub repository. For my project, I cloned hello-friend-ng theme from <a href="https://github.com/rhazdon/hugo-theme-hello-friend-ng.git">it&rsquo;s github repository</a> in my project&rsquo;s themes directory. As mentioned on <a href="https://themes.gohugo.io/hugo-theme-hello-friend-ng/">hello-friend-ng</a> website, I used following command to link this theme subproject with my main website project -</p>

<p><code>$ git submodule add https://github.com/rhazdon/hugo-theme-hello-friend-ng.git themes/hello-friend-ng</code></p>

<p>There is a benefit of linking your theme subproject with your theme&rsquo;s GitHub repository - whenever there will be any changes in your theme&rsquo;s code, you can very easily download them by using <code>git clone</code> command.</p>

<h3 id="step-6-generate-static-content-of-your-website">Step 6 - Generate static content of your website</h3>

<p><code>hugo -t theme-name</code> command generates static content of your website in <code>/public</code> directory. If you will link this directory with the repository created under step 1.1 the by just pushing that generated static web content, your website will be hosted on GitHubPages. Steps to link your <code>/public</code> with GitHub repository are mentioned on your GitHub repository home page. Open that home page on your GitHub repository website and follow them.</p>

<p>Now add this github project as submodule with your main website project. Detailed steps are mentioned <a href="https://gohugo.io/hosting-and-deployment/hosting-on-github/">here</a>.</p>

<h3 id="useful-links">Useful Links</h3>

<ul>
<li><a href="https://www.youtube.com/watch?v=qtIqKaDlqXo&amp;list=PLLAZ4kZ9dFpOnyRlyS-liKL5ReHDcj4G3">Videos to learn GoHugo</a></li>
<li><a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#emphasis">Markdown cheatsheet</a></li>
<li><a href="https://gohugo.io/getting-started/installing/">GoHugo Installation steps</a></li>
<li><a href="https://gohugo.io/hosting-and-deployment/hosting-on-github/">GoHost Hugo site on GitHub</a></li>
</ul>
]]></content>
        </item>
        
    </channel>
</rss>
