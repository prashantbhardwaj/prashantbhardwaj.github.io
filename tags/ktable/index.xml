<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ktable on Prashant Bhardwaj</title>
    <link>/tags/ktable/</link>
    <description>Recent content in ktable on Prashant Bhardwaj</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>copyright@Prashant</copyright>
    <lastBuildDate>Sat, 24 Dec 2022 23:18:23 +0000</lastBuildDate><atom:link href="/tags/ktable/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka Streams - WIP</title>
      <link>/posts/kafka-streams-wip/</link>
      <pubDate>Sat, 24 Dec 2022 23:18:23 +0000</pubDate>
      
      <guid>/posts/kafka-streams-wip/</guid>
      <description>If any team is using Kafka as a message broker or event sourcing system or change logs or commit log; no matter what your use case is, you must be having producers and consumers. Now at the consumer side, to process the event stream, you&amp;rsquo;ll be having one of following 2 systems -
 Microservices using Kafka&amp;rsquo;s Producer and Consumer API, procssing one message at a time Full fledged stream processing applications using Streaming framework as explained just above.</description>
    </item>
    
  </channel>
</rss>
